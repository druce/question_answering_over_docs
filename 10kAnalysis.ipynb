{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://colab.research.google.com/drive/1uL1TdMbR4kqa0Ksrd_Of_jWSxWt1ia7o?usp=sharing#scrollTo=c48a272c-8e87-4740-9960-129d7d5943bb\n",
    "# https://betterprogramming.pub/llamaindex-deep-lake-for-financial-statement-analysis-954f2b789c8e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown, display\n",
    "from pathlib import Path\n",
    "\n",
    "from llama_index import download_loader, ServiceContext, StorageContext, load_index_from_storage, GPTVectorStoreIndex\n",
    "from llama_index import GPTListIndex, LLMPredictor\n",
    "from llama_index.composability import ComposableGraph\n",
    "\n",
    "from langchain import OpenAI\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set text wrapping (for colab?)\n",
    "# from IPython.display import HTML, display\n",
    "\n",
    "# def set_css():\n",
    "#   display(HTML('''\n",
    "#   <style>\n",
    "#     pre {\n",
    "#         white-space: pre-wrap;\n",
    "#     }\n",
    "#   </style>\n",
    "#   '''))\n",
    "# get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir uber\n",
    "# mkdir tmp\n",
    "# wget https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1 -O tmp/UBER.zip\n",
    "# unzip tmp/UBER.zip -d tmp\n",
    "# mv tmp/UBER/*.html ./uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/drucev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/drucev/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "INFO:unstructured:Reading document from string ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document from string ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unstructured:Reading document ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unstructured:Reading document from string ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document from string ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unstructured:Reading document ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unstructured:Reading document from string ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document from string ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unstructured:Reading document ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unstructured:Reading document from string ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document from string ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unstructured:Reading document ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document ...\n"
     ]
    }
   ],
   "source": [
    "# extract raw text from html\n",
    "# https://unstructured.io ; https://github.com/Unstructured-IO/unstructured\n",
    "UnstructuredReader = download_loader(\"UnstructuredReader\", refresh_cache=True)\n",
    "\n",
    "loader = UnstructuredReader()\n",
    "doc_set = {}\n",
    "all_docs = []\n",
    "years = [2022, 2021, 2020, 2019]\n",
    "for year in years:\n",
    "    year_docs = loader.load_data(file=Path(f'./uber/UBER_{year}.html'), split_documents=False)\n",
    "    # insert year metadata into each year\n",
    "    for d in year_docs:\n",
    "        d.extra_info = {\"year\": year}\n",
    "    doc_set[year] = year_docs\n",
    "    all_docs.extend(year_docs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service_context talks to openai (or other llm)\n",
    "# https://gpt-index.readthedocs.io/en/latest/reference/service_context.html\n",
    "\n",
    "service_context = ServiceContext.from_defaults(chunk_size_limit=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize simple vector indices + global vector index\n",
    "# NOTE: don't run this cell if the indices are already loaded! \n",
    "# generates many calls to openai to compute embedding vectors\n",
    "# https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/SimpleIndexDemo.html\n",
    "\n",
    "# index_set = {}\n",
    "\n",
    "# for year in years:    \n",
    "#     print(datetime.now(), 'indexing', year)\n",
    "#     index_id = \"index_%d\" % year\n",
    "#     cur_index = GPTVectorStoreIndex.from_documents(doc_set[year]\n",
    "#                                                    service_context=service_context)\n",
    "#     index_set[year] = cur_index\n",
    "#     cur_index.storage_context.persist(index_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 09:51:45.613594 loading 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all indices.\n",
      "2023-05-07 09:51:45.923216 loading 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all indices.\n",
      "2023-05-07 09:51:46.274689 loading 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all indices.\n",
      "2023-05-07 09:51:46.615722 loading 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "# load previously created indexes\n",
    "index_set = {}\n",
    "for year in years:\n",
    "    index_id = \"index_%d\" % year\n",
    "    print(datetime.now(), 'loading', year)\n",
    "    # load index\n",
    "    cur_index = load_index_from_storage(StorageContext.from_defaults(persist_dir=index_id))\n",
    "    index_set[year] = cur_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this global index is a single vector store containing all documents\n",
    "# Only relevant for the section below: \"Can a single vector index answer questions across years?\"\n",
    "# this generates many calls, and should be possible to duplicate by composing global index from individual indexes\n",
    "\n",
    "# global_index = GPTVectorStoreIndex.from_documents(all_docs,\n",
    "#                                                   service_context=service_context)\n",
    "# global_index.storage_context.persist(\"index_global\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "global_index = load_index_from_storage(StorageContext.from_defaults(persist_dir=\"index_global\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1502 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 1502 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "The biggest risk factors in 2020 included:\n",
      "- Changes in normal business practices necessitated by the outbreak and related governmental actions.\n",
      "- Privacy, cybersecurity and fraud risks associated with increased remote working.\n",
      "- Legal or regulatory challenges to our understanding of applicable legal and regulatory requirements.\n",
      "- Heightened risks associated with the launch of new services, features, or health and safety requirements.\n",
      "- Financial impacts of the COVID-19 pandemic, including reductions in workforce and changes to pricing models.\n",
      "- Uncertainty around the ultimate impact of the pandemic on our future business operations, liquidity, financial condition, and results of operations.\n",
      "- Potential fines or other enforcement measures resulting from legal or regulatory challenges.\n",
      "- Adverse impacts on our business partners and third-party vendors.\n",
      "- Extreme volatility in financial markets.\n",
      "- Risk of Drivers being classified as employees, workers or quasi-employees.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index_set[2020].as_query_engine(retriever_mode=\"embedding\", \n",
    "                                               service_context=service_context,                                     \n",
    "                                               similarity_top_k=3,\n",
    "                                               verbose=True,\n",
    "                                              )\n",
    "query = \"What were some of the biggest risk factors in 2020?\"\n",
    "response = query_engine.query(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1371 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 1371 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "Some of the significant acquisitions include the acquisition of Careem, the purchase of a controlling interest in Cornershop, the acquisition of Postmates, the acquisition of Routematch Holdings, Inc., and the acquisition of Cornershop Global LLC.\n"
     ]
    }
   ],
   "source": [
    "query = \"What were some of the signifcant acquisitions?\"\n",
    "response = query_engine.query(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 12 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total embedding token usage: 12 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1700 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 1700 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1700 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 1700 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "2019:\n",
      "- Drivers being classified as employees, workers or quasi-employees instead of independent contractors.\n",
      "- High competition in the mobility, delivery, and logistics industries.\n",
      "- Lowering of fares or service fees to remain competitive.\n",
      "- Security breaches exposing the company to liability and increasing the risk of litigation and governmental investigation.\n",
      "\n",
      "2020:\n",
      "- Drivers being classified as employees, workers or quasi-employees instead of independent contractors.\n",
      "- High competition in the mobility, delivery, and logistics industries.\n",
      "- Lowering of fares or service fees to remain competitive.\n",
      "- Security breaches exposing the company to liability and increasing the risk of litigation and governmental investigation.\n",
      "- Inability to anticipate and prevent security techniques.\n",
      "- Potential misappropriation of confidential, proprietary, or personal information.\n",
      "\n",
      "2022:\n",
      "- Drivers being classified as employees, workers or quasi-employees instead of independent contractors.\n",
      "- High competition in the mobility, delivery, and logistics industries.\n",
      "- Lowering of fares or service fees to remain competitive.\n",
      "- Security breaches exposing the company to liability and increasing the risk of litigation and governmental investigation.\n",
      "- Inability to anticipate and prevent security techniques.\n",
      "- Potential misappropriation of confidential, proprietary, or personal information.\n",
      "- Potential liability not covered by insurance.\n"
     ]
    }
   ],
   "source": [
    "query_all = global_index.as_query_engine(retriever_mode=\"embedding\", \n",
    "                                         service_context=service_context,   \n",
    "                                         similarity_top_k=3,\n",
    "#                                          response_mode=\"tree_summarize\",\n",
    "                                         verbose=True,\n",
    "                                    )\n",
    "risk_query_str = \"What are some of the biggest risk factors in each year?\"\n",
    "response = query_all.query(risk_query_str)\n",
    "print(str(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summary text for each doc\n",
    "summaries = {}\n",
    "for year in years:\n",
    "    summaries[year] = f\"UBER 10-k Filing for {year} fiscal year\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of output tokens\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, max_tokens=512))\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "graph = ComposableGraph.from_indices(\n",
    "    GPTListIndex,\n",
    "    [index_set[y] for y in years],\n",
    "    [summaries[y] for y in years],\n",
    "    service_context=service_context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_query_engines = {\n",
    "    my_index.index_id: my_index.as_query_engine(\n",
    "        similarity_top_k=1,\n",
    "        response_mode=\"tree_summarize\",\n",
    "    )\n",
    "    for my_index in [index_set[y] for y in years]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_query_str = (\n",
    "    \"Describe the current risk factors. If the year is provided in the information, \"\n",
    "    \"provide that as well. If the context contains risk factors for multiple years, \"\n",
    "    \"explicitly provide the following:\\n\"\n",
    "    \"- A description of the risk factors for each year\\n\"\n",
    "    \"- A summary of how these risk factors are changing across years\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 60 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total embedding token usage: 60 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 634 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 634 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 634 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 634 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 709 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 709 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 709 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 709 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 634 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 634 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 634 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 634 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 793 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 793 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 793 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 793 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1027 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 1027 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "The current risk factors for 2021 include the impact of the COVID-19 pandemic on parts of our business, the potential for Drivers to be classified as employees, workers or quasi-employees instead of independent contractors, the highly competitive nature of the mobility, delivery, and logistics industries, and the need to lower fares or service fees and offer Driver incentives and consumer discounts and promotions in order to remain competitive in certain markets. We have also incurred significant losses since inception, including in the United States and other major markets. \n",
      "\n",
      "The risk factors for 2020 are outlined in Item 1A of the information provided. These risk factors include unresolved staff comments, properties, legal proceedings, and mine safety disclosures. \n",
      "\n",
      "The risk factors for 2019 include interest rate risk, investment risk, and foreign currency risk. Interest rate risk relates to the 2016 Term Loan Facility and 2018 Term Loan Facility, which are floating rate notes and are carried at amortized cost. Investment risk is managed by an investment policy objective that aims to preserve capital and meet liquidity requirements without significantly increasing risk. As of December 31, 2019, cash and cash equivalents including restricted cash and cash equivalents totaled $12.1 billion, and marketable debt securities classified as short-term investments totaled $440 million.\n",
      "\n",
      "The risk factors for 2018 include cash and cash equivalents including restricted cash and cash equivalents totaling $8.2 billion. This is a decrease of $3.9 billion from December 31, 2019.\n",
      "\n",
      "Compared to prior years, the risk factors have not changed significantly. The COVID-19 pandemic has had an adverse effect on parts of our business, and the mobility, delivery, and logistics industries remain highly competitive. We have also continued to incur significant losses since inception.\n"
     ]
    }
   ],
   "source": [
    "query_engine = graph.as_query_engine(custom_query_engines=custom_query_engines)\n",
    "response = query_engine.query(risk_query_str)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The current risk factors for 2021 include the impact of the COVID-19 pandemic on parts of our business, the potential for Drivers to be classified as employees, workers or quasi-employees instead of independent contractors, the highly competitive nature of the mobility, delivery, and logistics industries, and the need to lower fares or service fees and offer Driver incentives and consumer discounts and promotions in order to remain competitive in certain markets. We have also incurred significant losses since inception, including in the United States and other major markets. \n",
      "\n",
      "The risk factors for 2020 are outlined in Item 1A of the information provided. These risk factors include unresolved staff comments, properties, legal proceedings, and mine safety disclosures. \n",
      "\n",
      "The risk factors for 2019 include interest rate risk, investment risk, and foreign currency risk. Interest rate risk relates to the 2016 Term Loan Facility and 2018 Term Loan Facility, which are floating rate notes and are carried at amortized cost. Investment risk is managed by an investment policy objective that aims to preserve capital and meet liquidity requirements without significantly increasing risk. As of December 31, 2019, cash and cash equivalents including restricted cash and cash equivalents totaled $12.1 billion, and marketable debt securities classified as short-term investments totaled $440 million.\n",
      "\n",
      "The risk factors for 2018 include cash and cash equivalents including restricted cash and cash equivalents totaling $8.2 billion. This is a decrease of $3.9 billion from December 31, 2019.\n",
      "\n",
      "Compared to prior years, the risk factors have not changed significantly. The COVID-19 pandemic has had an adverse effect on parts of our business, and the mobility, delivery, and logistics industries remain highly competitive. We have also continued to incur significant losses since inception.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: b5b1a2c0-3346-4fac-8eed-e5ee54b6c5bf): \n",
      "The current risk factors for 2022 include: \n",
      "- Drivers being classified as employees, workers or ...\n",
      "\n",
      "> Source (Doc id: 6b090db1-3c38-4a41-bd88-24191a2753eb): \n",
      "The current risk factors for 2021 include the COVID-19 pandemic and the impact of a\n"
     ]
    }
   ],
   "source": [
    "print(response_summary.get_formatted_sources()[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 60 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total embedding token usage: 60 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1606 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 1606 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "For the year 2022, the risk factors include: \n",
      "\n",
      "- Drivers being classified as employees, workers or quasi-employees instead of independent contractors.\n",
      "- The mobility, delivery, and logistics industries being highly competitive, with well-established and low-cost alternatives that have been available for decades, low barriers to entry, low switching costs, and well-capitalized competitors in nearly every major geographic region.\n",
      "- Lowering of fares or service fees, and offering of significant Driver incentives and consumer discounts and promotions in order to remain competitive in certain markets.\n",
      "- Incurring significant losses since inception, including in the United States and other major markets.\n",
      "- Attracting and maintaining a critical mass of Drivers, consumers, merchants, Shippers, and Carriers.\n",
      "- Retaining and attracting high-quality personnel, and continued attrition, future attrition, or unsuccessful succession planning.\n",
      "- Maintaining and enhancing brand and reputation.\n",
      "- Historical workplace culture and forward-leaning approach creating operational, compliance, and cultural challenges.\n",
      "- Impact of economic conditions, including the resulting effect on discretionary consumer spending.\n",
      "- Potential impacts of pandemics or other catastrophic events.\n",
      "\n",
      "These risk factors have remained largely the same since the year 2022, with the addition of potential impacts of pandemics or other catastrophic events.\n"
     ]
    }
   ],
   "source": [
    "response_tmp = index_set[2022].as_query_engine(retriever_mode=\"embedding\", \n",
    "                                               service_context=service_context,                                     \n",
    "                                               similarity_top_k=3,\n",
    "                                               verbose=True,\n",
    "                                              ).query(risk_query_str)\n",
    "print(str(response_tmp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total LLM token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 60 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [retrieve] Total embedding token usage: 60 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 2107 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total LLM token usage: 2107 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "Year 2020:\n",
      "The risk factors include Drivers being classified as employees, workers or quasi-employees instead of independent contractors, the mobility, delivery, and logistics industries being highly competitive, and the need to lower fares or service fees and offer significant Driver incentives and consumer discounts and promotions to remain competitive.\n",
      "\n",
      "Year 2021:\n",
      "The risk factors include the COVID-19 pandemic and the impact of actions to mitigate the pandemic, Drivers being classified as employees, workers or quasi-employees instead of independent contractors, the mobility, delivery, and logistics industries being highly competitive, and the need to lower fares or service fees and offer significant Driver incentives and consumer discounts and promotions to remain competitive.\n",
      "\n",
      "Year 2022:\n",
      "The risk factors include Drivers being classified as employees, workers or quasi-employees instead of independent contractors, the mobility, delivery, and logistics industries being highly competitive, and the need to lower fares or service fees and offer significant Driver incentives and consumer discounts and promotions to remain competitive.\n",
      "\n",
      "Summary:\n",
      "The risk factors for 2020 and 2022 are the same, while the risk factors for 2021 include the additional risk of the COVID-19 pandemic and the impact of actions to mitigate the pandemic.\n"
     ]
    }
   ],
   "source": [
    "response = global_index.as_query_engine(retriever_mode=\"embedding\", \n",
    "                                        service_context=service_context,   \n",
    "                                        similarity_top_k=4,\n",
    "                                        verbose=True,\n",
    "                                       ).query(risk_query_str)\n",
    "print(str(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama20",
   "language": "python",
   "name": "llama20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
