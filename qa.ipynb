{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.154'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import dotenv\n",
    "\n",
    "import langchain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# load secrets from .env into environment variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "langchain.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_obj = openai.Model.list()\n",
    "# sorted([m['id'] for m in models_obj['data']])\n",
    "\n",
    "# add pinecone\n",
    "# do the csv thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # doesn't work, maybe see https://stackoverflow.com/questions/66990912/import-error-cannot-import-name-open-filename-from-pdfminer-utils\n",
    "# hftcdir = '/Users/drucev/notebooks/llama2/llama_index/examples/vector_indices/hftc'\n",
    "# documents = DirectoryLoader(hftcdir).load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21622"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hftcdir = '/Users/drucev/projects/question_answering_over_docs/hftc'\n",
    "\n",
    "documents = None\n",
    "count = 0\n",
    "for f in glob.glob('%s/*' % hftcdir):\n",
    "    count += 1\n",
    "#     print(f)\n",
    "    if documents is None:\n",
    "        documents = TextLoader(f).load()\n",
    "    else:\n",
    "        documents.extend(TextLoader(f).load())\n",
    "\n",
    "print(count)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 splitting 2023-05-05 10:59:23.775477\n",
      "2 getting embeddings 2023-05-05 10:59:24.340225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: chromadb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 creating index 2023-05-05 10:59:24.783059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2630b0aedd6f485883ce398bc6f3cbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='100%'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 instantiate retriever 2023-05-05 11:03:39.111844\n"
     ]
    }
   ],
   "source": [
    "# embedding_model = 'text-embedding-ada-002'   # default\n",
    "\n",
    "# split the documents into chunks\n",
    "print(1, 'splitting', datetime.now())\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# load embeddings into vector db\n",
    "print(2, 'getting embeddings', datetime.now())\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# create the vectorestore to use as the index\n",
    "print(3, 'creating index', datetime.now())\n",
    "persist_directory = 'chromadb'\n",
    "vectordb = Chroma.from_documents(documents=texts, embedding=embeddings, persist_directory=persist_directory)\n",
    "vectordb.persist()\n",
    "\n",
    "# expose this index in a retriever interface\n",
    "print(4, 'instantiate retriever', datetime.now())\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: chromadb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ebd50915bb4ba6a65f4de8585ad170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='100%'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load from local directory\n",
    "embeddings = OpenAIEmbeddings()\n",
    "persist_directory = 'chromadb'\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a chain to answer questions\n",
    "qa_model = 'gpt-3.5-turbo-0301'\n",
    "\n",
    "llm = ChatOpenAI(model_name=qa_model, \n",
    "                 temperature=0.3,\n",
    "                )\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=retriever,\n",
    "                                 return_source_documents=True\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One endpoint protection product mentioned in the context is Crowdstrike. However, there are many other endpoint protection and EDR products available in the market, such as Carbon Black, SentinelOne, McAfee Endpoint Security, Symantec Endpoint Protection, Trend Micro Apex One, and many more.\n"
     ]
    }
   ],
   "source": [
    "query = \"what are the names of some endpoint protection or endpoint detection and response or EDR products?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mentioned Managed Service Providers or MSPs are AlphaServe, CDI, and Agio.\n"
     ]
    }
   ],
   "source": [
    "query = \"what are the names of mentioned Managed Service Providers or MSPs?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context does not mention any specific MDRs or MSSPs by name. It provides criteria for selecting an MDR or MSSP, but it does not recommend any particular company.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what are the names of mentioned MDRs or MSSPs?\"\n",
    "result = qa({\"query\": query})\n",
    "result['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result['source_documents'][0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result['source_documents'][0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat /Users/drucev/notebooks/llama2/llama_index/examples/vector_indices/hftc/20200805-iYejQDYtPG6DKsu3Qouy.txt\n",
    "# result['source_documents'][1].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab emails from Gmail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplegmail import Gmail\n",
    "from simplegmail.query import construct_query\n",
    "from datetime import datetime\n",
    "\n",
    "print(datetime.now())\n",
    "gmail = Gmail()\n",
    "\n",
    "# Unread messages in inbox with label \"Work\"\n",
    "labels = gmail.list_labels()\n",
    "\n",
    "# work_label = list(filter(lambda x: x.name == 'hedgefundtech', labels))[0]\n",
    "# messages = gmail.get_unread_inbox(labels=[work_label])\n",
    "\n",
    "# For even more control use queries:\n",
    "# Messages that are: newer than 2 days old, unread, labeled \"Finance\" or both \"Homework\" and \"CS\"\n",
    "query_params = {\n",
    "    \"labels\":[[\"hedgefundtech\"]]\n",
    "}\n",
    "\n",
    "messages = gmail.get_messages(query=construct_query(query_params))\n",
    "print(len(messages))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "\n",
    "outdir = 'hftc/'\n",
    "\n",
    "for message in messages:\n",
    "\n",
    "    sendemail, subject, senddate, date_object = None, None, None, None\n",
    "    try:\n",
    "        # don't get or save sender\n",
    "#         if 'X-Sender' in message.headers:\n",
    "#             sendemail = message.headers['X-Sender']\n",
    "#         if not sendemail:\n",
    "#             sendemail =  message.headers['From']\n",
    "#             match = re.search(r'<(.+?)>', sendemail)\n",
    "#             if match:\n",
    "#                 sendemail = match.group(1)\n",
    "#         if not sendemail:\n",
    "#             match = re.search(r'<(.+?)>', message.sender)\n",
    "#             if match:\n",
    "#                 sendemail = match.group(1)\n",
    "#         if not sendemail:\n",
    "#             sendemail =  message.sender\n",
    "            \n",
    "        subject = message.subject[16:] if message.subject else ''\n",
    "        senddate = message.date\n",
    "        date_object = datetime.strptime(senddate, '%Y-%m-%d %H:%M:%S%z')   \n",
    "        # print(date_object, sendemail, subject)\n",
    "        \n",
    "        sendbody = message.plain[:1000] if message.plain else '' # or message.html\n",
    "\n",
    "        rnd = ''.join(random.choices(string.ascii_uppercase + string.ascii_lowercase + string.digits, k=20))\n",
    "        filename = datetime.strftime(date_object, \"%Y%d%m\") + '-' + rnd + '.txt'\n",
    "#         print(filename)\n",
    "        \n",
    "        with open(outdir + filename, 'w') as outfile: \n",
    "            outfile.write('Date: %s\\n' % senddate)\n",
    "            outfile.write('Subject: %s\\n\\n' % subject)\n",
    "            outfile.write(sendbody)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
