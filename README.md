# question_answering_over_docs
Question answering with ChatGPT and LlamaIndex and Langchain over your own docs

- qa.ipynb: Langchain

- qa_llama.ipynb: LlamaIndex and Pinecone for vector storage

- qa_llama-hf-chroma.ipynb: LlamaIndex, Chroma for local storage, and Huggingface model (runs slow)

- 10kAnalysis.ipynb: [LlamaIndex 10k example updated to reflect 0.6 refactor](https://betterprogramming.pub/llamaindex-deep-lake-for-financial-statement-analysis-954f2b789c8e
)
